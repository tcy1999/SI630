{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI630 Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kaggle User Name: chenyuntao \n",
    "* Name Displayed: Chenyun Tao \n",
    "* Uniqname: cyuntao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('my_word2vec.wv', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7', 0.8617218732833862),\n",
       " ('023', 0.8496308922767639),\n",
       " ('545', 0.8398237824440002),\n",
       " ('938', 0.83519446849823),\n",
       " ('037', 0.8346812725067139),\n",
       " ('791', 0.8328269720077515),\n",
       " ('097', 0.8319663405418396),\n",
       " ('909', 0.8264710903167725),\n",
       " ('1', 0.8264130353927612),\n",
       " ('852', 0.8248751163482666)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('novellas', 0.8293923139572144),\n",
       " ('anthologies', 0.8185344338417053),\n",
       " ('essays', 0.8104189038276672),\n",
       " ('illustrations', 0.7848616242408752),\n",
       " ('novels', 0.7826084494590759),\n",
       " ('collections', 0.7822340726852417),\n",
       " ('articles', 0.779187023639679),\n",
       " ('reprints', 0.7691074013710022),\n",
       " ('publications', 0.7676923274993896),\n",
       " ('taxa', 0.7632808685302734)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 0.7540034055709839),\n",
       " ('hundredths', 0.7282611727714539),\n",
       " ('kinimaka', 0.696230411529541),\n",
       " ('clasps', 0.6880671977996826),\n",
       " ('inactivity', 0.6861849427223206),\n",
       " ('armband', 0.6746704578399658),\n",
       " ('truce', 0.6711289286613464),\n",
       " ('misadventure', 0.667199432849884),\n",
       " ('bogey', 0.6593464612960815),\n",
       " ('fluckey', 0.6590462327003479)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elisabeth', 0.7705016732215881),\n",
       " ('gudrun', 0.7614984512329102),\n",
       " ('tine', 0.7507264614105225),\n",
       " ('franziska', 0.7421220541000366),\n",
       " ('ivanovna', 0.7388003468513489),\n",
       " ('isabelle', 0.7375069260597229),\n",
       " ('kournikova', 0.7367249131202698),\n",
       " ('elise', 0.7362877130508423),\n",
       " ('inga', 0.7359388470649719),\n",
       " ('johanna', 0.734180212020874)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('anna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('microsoft', 0.762705385684967),\n",
       " ('nyse', 0.7428861856460571),\n",
       " ('lucasfilm', 0.7327085137367249),\n",
       " ('jpmorgan', 0.7212052345275879),\n",
       " ('ddb', 0.7090804576873779),\n",
       " ('msg', 0.7024335861206055),\n",
       " ('shiseido', 0.6980329155921936),\n",
       " ('aol', 0.6937880516052246),\n",
       " ('foxsports', 0.6900680661201477),\n",
       " ('mozilla', 0.6882199048995972)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chemistry', 0.8859132528305054),\n",
       " ('paleontology', 0.867053747177124),\n",
       " ('astrophysics', 0.8587157726287842),\n",
       " ('zoology', 0.8538668155670166),\n",
       " ('geophysics', 0.8518619537353516),\n",
       " ('biophysics', 0.8510938882827759),\n",
       " ('geology', 0.8474372029304504),\n",
       " ('biology', 0.8412570953369141),\n",
       " ('humanities', 0.8356377482414246),\n",
       " ('theoretical', 0.8329718708992004)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('physics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('surely', 0.8762216567993164),\n",
       " ('malicious', 0.8553721308708191),\n",
       " ('inexplicable', 0.8485351204872131),\n",
       " ('owe', 0.844571053981781),\n",
       " ('likable', 0.8443453311920166),\n",
       " ('delete', 0.8442380428314209),\n",
       " ('unreasonable', 0.8414052724838257),\n",
       " ('heinous', 0.841387152671814),\n",
       " ('prejudiced', 0.8342485427856445),\n",
       " ('sickening', 0.8329619765281677)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('ridiculous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('montana', 0.8423749804496765),\n",
       " ('arkansas', 0.8313051462173462),\n",
       " ('kentucky', 0.8308364152908325),\n",
       " ('dakota', 0.8237232565879822),\n",
       " ('fayetteville', 0.8157213926315308),\n",
       " ('mississippi', 0.8141648769378662),\n",
       " ('duluth', 0.8041296005249023),\n",
       " ('alabama', 0.803572416305542),\n",
       " ('lewiston', 0.8018585443496704),\n",
       " ('virginia', 0.800946831703186)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('michigan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dictatorship', 0.8642090559005737),\n",
       " ('communists', 0.8238113522529602),\n",
       " ('hitler', 0.7834300398826599),\n",
       " ('ceauşescu', 0.7785800099372864),\n",
       " ('persecution', 0.7748729586601257),\n",
       " ('separatist', 0.7742667198181152),\n",
       " ('pact', 0.7733154892921448),\n",
       " ('pinochet', 0.7670925855636597),\n",
       " ('ceaușescu', 0.7637039422988892),\n",
       " ('repressions', 0.7629903554916382)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word('regime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the predicted words seem to be semantically similar to the target words, but the predictions for the frequent words are better than those for occasional words and rare words. It also seems that the model could do better predictions on some special words whose meanings are specific, and might have specific contexts, for example, 'michigan'. Although 'michigan' is a rare word, the predicted words look quite good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walking'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('jump', 'walk', 'jumping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'languages'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('book', 'language', 'books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'korean'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('japan', 'korea', 'japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tokyo'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('korea', 'japan', 'seoul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meager'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('big', 'large', 'bigger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some of the analogies worked, while some not. In the 5 analogies that I have tried, the model finds 'walking' is to 'walk' as 'jumping' is to 'jump', 'languages' is to 'language' as 'books' is to 'book', 'korean' is to 'korea' as 'japanese' is to 'japan', 'tokyo' is to 'japan' as 'seoul' is to 'korea'. However, given 'bigger' is to 'big', the model picks 'meager' to 'large'. Although 'meager' is in the \"-er\" form, this should not be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id  word1        word2\n",
       "0        0    old          new\n",
       "1        1  smart  intelligent\n",
       "2        2   hard    difficult\n",
       "3        3  happy     cheerful\n",
       "4        4   hard         easy"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs = pd.read_csv('word_pairs_to_estimate_similarity.test.csv') \n",
    "word_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_scores = []\n",
    "for index, row in word_pairs.iterrows():\n",
    "    word1 = row[1]\n",
    "    word2 = row[2]\n",
    "    if word1 not in word_vectors:\n",
    "        word1 = '<UNK>'\n",
    "    if word2 not in word_vectors:\n",
    "        word2 = '<UNK>'\n",
    "    sim_scores.append(word_vectors.similarity(word1, word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(word_pairs['pair_id'])\n",
    "result['similarity'] = sim_scores\n",
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_vectors = KeyedVectors.load_word2vec_format('my_word2vec_synonyms.wv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deputy', 0.8019633293151855),\n",
       " ('kpmg', 0.7767941951751709),\n",
       " ('advisor', 0.7703201770782471),\n",
       " ('auditor', 0.7609075903892517),\n",
       " ('administrative', 0.7436810731887817),\n",
       " ('appointee', 0.7381704449653625),\n",
       " ('consultant', 0.7373884916305542),\n",
       " ('chief', 0.7365993857383728),\n",
       " ('undersecretary', 0.7252454161643982),\n",
       " ('liaison', 0.7233219742774963)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"adviser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('consultant', 0.8524190187454224),\n",
       " ('advisor', 0.8397467732429504),\n",
       " ('chief', 0.787283718585968),\n",
       " ('economist', 0.7719884514808655),\n",
       " ('strategist', 0.7714995741844177),\n",
       " ('kpmg', 0.7626684308052063),\n",
       " ('boss', 0.7369043231010437),\n",
       " ('statistician', 0.7354175448417664),\n",
       " ('samora', 0.73353511095047),\n",
       " ('directorate', 0.7304761409759521)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"adviser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logistical', 0.8019434809684753),\n",
       " ('airway', 0.7648997902870178),\n",
       " ('sanitary', 0.7633872628211975),\n",
       " ('dewatering', 0.7564762830734253),\n",
       " ('epidemiologic', 0.7535840272903442),\n",
       " ('facilitating', 0.7523698806762695),\n",
       " ('competitiveness', 0.7465103268623352),\n",
       " ('radioisotopes', 0.7454443573951721),\n",
       " ('solving', 0.7447012662887573),\n",
       " ('organisational', 0.7441443800926208)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"economical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('economic', 0.9121019840240479),\n",
       " ('ecological', 0.8331916332244873),\n",
       " ('economy', 0.8126458525657654),\n",
       " ('climate', 0.8002585768699646),\n",
       " ('globalization', 0.7916080355644226),\n",
       " ('policy', 0.7913529276847839),\n",
       " ('socioeconomic', 0.7870862483978271),\n",
       " ('cohesion', 0.7848232984542847),\n",
       " ('economies', 0.7820599675178528),\n",
       " ('disparities', 0.7818484902381897)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"economical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conductivity', 0.8310834169387817),\n",
       " ('inhibitory', 0.8119741082191467),\n",
       " ('incremental', 0.8075635433197021),\n",
       " ('gases', 0.7931780219078064),\n",
       " ('porous', 0.7930848002433777),\n",
       " ('simulations', 0.7930310964584351),\n",
       " ('injection', 0.7905918955802917),\n",
       " ('diffusion', 0.7883409857749939),\n",
       " ('methods', 0.7853349447250366),\n",
       " ('reassessment', 0.782145619392395)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('invasive', 0.8119388818740845),\n",
       " ('enhance', 0.7985661625862122),\n",
       " ('stimulation', 0.7984791994094849),\n",
       " ('manipulation', 0.7977747917175293),\n",
       " ('integrate', 0.7950735688209534),\n",
       " ('discover', 0.7936634421348572),\n",
       " ('electrolytes', 0.7912244200706482),\n",
       " ('emphasize', 0.7909663319587708),\n",
       " ('antibiotic', 0.7858322858810425),\n",
       " ('immune', 0.7857041358947754)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2', 0.9241558313369751),\n",
       " ('023', 0.8629616498947144),\n",
       " ('7', 0.8623941540718079),\n",
       " ('9', 0.8603189587593079),\n",
       " ('yel', 0.8593716025352478),\n",
       " ('8', 0.8487160205841064),\n",
       " ('wcq', 0.8475887179374695),\n",
       " ('6', 0.8417019248008728),\n",
       " ('inzell', 0.8363901972770691),\n",
       " ('492', 0.8281565308570862)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8', 0.8649346232414246),\n",
       " ('trey', 0.853675365447998),\n",
       " ('septet', 0.852579653263092),\n",
       " ('eight', 0.8394075632095337),\n",
       " ('seven', 0.8384681940078735),\n",
       " ('four', 0.838271975517273),\n",
       " ('v', 0.836565375328064),\n",
       " ('triad', 0.8355855941772461),\n",
       " ('troika', 0.833070695400238),\n",
       " ('7', 0.8313018083572388)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('immediately', 0.7232730984687805),\n",
       " ('whereupon', 0.7148445248603821),\n",
       " ('oai', 0.6885701417922974),\n",
       " ('torstensson', 0.6845402121543884),\n",
       " ('faller', 0.6814539432525635),\n",
       " ('bandmann', 0.6697770357131958),\n",
       " ('afterward', 0.6655863523483276),\n",
       " ('thereafter', 0.663615882396698),\n",
       " ('yorihito', 0.6610944271087646),\n",
       " ('houstoun', 0.6602509021759033)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"afterwards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('after', 0.7626321315765381),\n",
       " ('afterward', 0.7478715181350708),\n",
       " ('subsequently', 0.7364693880081177),\n",
       " ('earlier', 0.7018415927886963),\n",
       " ('before', 0.6789159774780273),\n",
       " ('later', 0.646862268447876),\n",
       " ('curtly', 0.615157961845398),\n",
       " ('bons', 0.6011383533477783),\n",
       " ('parsemain', 0.6007453799247742),\n",
       " ('thenceforth', 0.5835322141647339)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"afterwards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nestlé', 0.7566994428634644),\n",
       " ('candy', 0.7299879193305969),\n",
       " ('jeep', 0.6904927492141724),\n",
       " ('motorcity', 0.6874257326126099),\n",
       " ('chicken', 0.683999240398407),\n",
       " ('tuff', 0.6827149987220764),\n",
       " ('bucket', 0.6823759078979492),\n",
       " ('puppy', 0.6819471120834351),\n",
       " ('chrysler', 0.6813479065895081),\n",
       " ('apple', 0.6784874796867371)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wine', 0.7509880065917969),\n",
       " ('apple', 0.7420293688774109),\n",
       " ('chicken', 0.7248697280883789),\n",
       " ('asterix', 0.7106896638870239),\n",
       " ('soya', 0.7082656025886536),\n",
       " ('chevron', 0.707973837852478),\n",
       " ('disney', 0.7070032358169556),\n",
       " ('tails', 0.7015137076377869),\n",
       " ('opulence', 0.6969329118728638),\n",
       " ('eyewear', 0.6911447048187256)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('competitively', 0.7333688735961914),\n",
       " ('skied', 0.7225421667098999),\n",
       " ('trampoline', 0.7103570699691772),\n",
       " ('skiing', 0.7035570740699768),\n",
       " ('mtb', 0.6923143267631531),\n",
       " ('sculling', 0.6906573176383972),\n",
       " ('bbq', 0.6888306736946106),\n",
       " ('fives', 0.6866194605827332),\n",
       " ('softball', 0.6848371624946594),\n",
       " ('u25', 0.6801198124885559)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"swim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('swimming', 0.828518271446228),\n",
       " ('archery', 0.8174597024917603),\n",
       " ('biking', 0.7810505032539368),\n",
       " ('skiing', 0.7792401909828186),\n",
       " ('fencing', 0.7785387635231018),\n",
       " ('gymnastics', 0.7664653658866882),\n",
       " ('wayte', 0.7610089182853699),\n",
       " ('mtb', 0.7526524066925049),\n",
       " ('u12', 0.7354594469070435),\n",
       " ('curling', 0.7335914373397827)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_vectors.similar_by_word(\"swim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I choose 5 words in the `synonyms.txt` file, which are 'adviser', 'economical', 'use', '4', and 'afterwards', and 2 words that are not in the `synonyms.txt` file, which are 'swim' and 'pizza'.\n",
    "\n",
    "In my opinion, the new synonym-aware model produces slightly better vectors. For example, in the original model, most of the nearest neighbours for word '4' are numbers, and the rest are some meaningless words, but in the new synonym-aware model, we have more nearest neighbours in text, and most of them are related to the word '4' or other numbers. In addition, the nearest neighbours for the word 'swim' seem to be more related to it and sports. However, I think the improvements are not significant, since some of the similar words picked by the new model are still not so semantically related to the target words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
